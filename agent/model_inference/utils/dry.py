# from typing import Callable, Dict, List, Mapping, Optional, cast

# import mlx.core as mx
# from mind.inference.utils.reverse_z_algo import reverse_z_algorithm


# def dry_processing(
#     logits: mx.array,
#     dry_context: mx.array,
#     dry_multiplier: float = 1.0,
#     dry_base: float = 1.75,
#     dry_repetition_threshold: int = 2,
#     dry_penalty_look_back: int = 0,
#     dry_sequence_breakers: Optional[Dict[int, List[List[int]]]] = None,
#     debug_callback: Optional[Callable[[Mapping[int, float]], None]] = None
# ) -> mx.array:
#     """
#     Apply DRY logit processing to the given logits based on the provided dry context.

#     This function penalizes repeated sequences in the logits to encourage diversity in generated sequences.
#     It uses a reverse Z-algorithm to efficiently find repeated patterns and applies penalties based on
#     the length of these patterns.

#     Parameters:
#     - logits: The logits to be processed.
#     - dry_context: The context array used to determine repetition.
#     - dry_multiplier: Multiplier for the penalty applied to repeated sequences.
#     - dry_base: Base for the exponential penalty calculation.
#     - dry_repetition_threshold: Minimum number of tokens that can be repeated without penalty.
#     - dry_penalty_look_back: Number of tokens from the end of the context to consider for penalties.
#     - dry_sequence_breakers: Dictionary mapping tokens to sequences that reset repetition penalties.
#     - debug_callback: Optional callback for debugging.

#     Returns:
#     - An array of biases to be applied to the logits.
#     """

#     if dry_multiplier <= 0.0 or dry_base <= 1.0 or dry_context is None:
#         raise ValueError("Invalid input parameters: dry_multiplier must be > 0, dry_base must be > 1, and dry_context must be valid.")

#     n_ctx = dry_context.shape[0]
#     penalty_range = min(dry_penalty_look_back if dry_penalty_look_back > 0 else n_ctx, n_ctx)
#     context_length = min(n_ctx, penalty_range)

#     if context_length <= dry_repetition_threshold:
#         # No penalty if the context length is less than the allowed repetition threshold
#         return mx.zeros_like(logits)

#     last_tokens: List[int] = cast(List[int], dry_context[-context_length:].tolist())
#     dry_max_token_repeat: Dict[int, int] = {}

#     if dry_sequence_breakers is None:
#         dry_sequence_breakers = {}

#     if debug_callback is not None:
#         print(f"Input parameters: dry_multiplier={dry_multiplier}, dry_base={dry_base}, dry_repetition_threshold={dry_repetition_threshold}")
#         print(f"dry_penalty_look_back={dry_penalty_look_back}")
#         print(f"Logits shape: {logits.shape}")
#         print(f"DRY context size: {len(last_tokens)}")
#         print(f"Penalty Range: {penalty_range}, previous {context_length} tokens to consider for penalties")

#     dry_repeat_count = reverse_z_algorithm(
#         last_tokens,
#         dry_sequence_breakers,
#         context_length
#     )

#     # Iterate over dry_repeat_count and last_tokens, examining the maximum repeat length
#     # that would be generated by emitting each new token that would extend a sequence.
#     #
#     # Last N tokens: a b c c b c y a b c
#     # Repeat counts: 0 0 3 1 0 2 0 0 0 0
#     #
#     # For each non-zero, look ahead one token. This token, if emitted, would extend the repetition.
#     # (`a b c` becomes `a b c c`) and the repeat count goes from 3 -> 4
#     # (`c` becomes `c b`) and the repeat count goes from 1 -> 2
#     # (`b c` becomes `b c y`) and the repeat count goes from 2 -> 3
#     for idx, repeat_len in enumerate(dry_repeat_count):
#         if repeat_len >= dry_repetition_threshold:
#             if idx + 1 >= len(last_tokens):
#                 continue  # Skip if next token is out of bounds
#             token = last_tokens[idx + 1]
#             # Track the maximum sequence ending in this token.
#             if (token not in dry_sequence_breakers and
#                 (token not in dry_max_token_repeat or dry_max_token_repeat[token] < repeat_len)):
#                 dry_max_token_repeat[token] = repeat_len

#     if debug_callback is not None:
#         print(f"DRY max token repeat: {dry_max_token_repeat}")

#     FLOAT_MAX_LOG = 88.7228391
#     max_exponent = 0
#     if dry_base > 1.000001:
#         max_exponent = int(FLOAT_MAX_LOG / mx.log(mx.array([dry_base])))

#     biases: mx.array = mx.zeros_like(logits)
#     for token, longest_matched_length in dry_max_token_repeat.items():
#         repeat_exp = longest_matched_length - dry_repetition_threshold
#         if repeat_exp <= 0:
#             repeat_exp = 0  # Ensure non-negative exponent
#         if max_exponent > 0:
#             repeat_exp = min(repeat_exp, max_exponent)
#         bias = dry_multiplier * (dry_base ** repeat_exp)
#         biases[token] -= bias  # Apply bias

#     if debug_callback is not None and dry_max_token_repeat:
#         debug_callback(dry_max_token_repeat)

#     return biases


# if __name__ == "__main__":
#     logits = mx.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0])
#     dry_context = mx.array([2, 2, 3, 1, 2, 2, 3, 1, 2, 2])
#     sequence_breakers = {
#         1: []
#     }
#     biases = dry_processing(
#         logits,
#         dry_context,
#         dry_multiplier=2.0,
#         dry_base=1.75,
#         dry_repetition_threshold=2,
#         dry_penalty_look_back=0,
#         dry_sequence_breakers=sequence_breakers,
#         debug_callback=print
#     )
#     print(biases.tolist())
